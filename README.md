The GPT Model Comparison project is a Python-based tool designed to evaluate and compare the performance of various GPT models provided by OpenAI, such as GPT-3 and GPT-4, including their Turbo variants. This tool allows users to conduct systematic tests across different models using a unified interface that manages chat sessions, tracks message history, and enforces word limits. It supports both synchronous and asynchronous operations, catering to real-time and batch processing needs. The project aims to provide insights into the models' response quality, speed, and coherence, facilitating informed decisions for developers and researchers looking to choose the most suitable GPT model for specific applications. This comparison tool is essential for anyone involved in developing AI-driven conversational systems, offering a structured approach to assessing model capabilities and performance.